{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Notes\n- JPX_Model_LGBM_v20\n\n# To do list","metadata":{}},{"cell_type":"code","source":"# import libraries\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nimport os\nfrom os.path import isfile, isdir, join\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime, date\nfrom dateutil.relativedelta import relativedelta\nfrom bs4 import BeautifulSoup\nimport re\nfrom IPython.display import display\nfrom zipfile import ZipFile\nimport pickle\nimport unicodedata\nimport pytz\nfrom joblib import Parallel, delayed\nimport shutil\nimport difflib\nimport random\nimport math\nfrom shutil import copyfile\nimport itertools\nimport time\nfrom tqdm import tqdm\nimport collections\nfrom collections import deque\nimport gc\nimport seaborn as sns\nimport scipy.cluster.hierarchy as spc\n\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import ndcg_score, accuracy_score\n\nimport lightgbm as lgbm\nimport optuna\nfrom optuna import Trial, visualization\n\nimport matplotlib as mpl\nfrom matplotlib import pyplot as plt\n\nimport jpx_tokyo_market_prediction\n\nfrom utility_script import *\n\n!pip install ../input/ta-0101/ta-0.10.1-py3-none-any.whl\nimport ta\nfrom ta import add_all_ta_features\nfrom ta.utils import dropna\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', None)","metadata":{"_uuid":"2c45ee48-0594-488c-8a45-26a2e5510d83","_cell_guid":"5ae9011f-40e6-497b-a6be-61b748ce1d2d","collapsed":false,"_kg_hide-input":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-03T08:47:41.460566Z","iopub.execute_input":"2022-07-03T08:47:41.461240Z","iopub.status.idle":"2022-07-03T08:48:14.987334Z","shell.execute_reply.started":"2022-07-03T08:47:41.461183Z","shell.execute_reply":"2022-07-03T08:48:14.986164Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}},{"name":"stdout","text":"Processing /kaggle/input/ta-0101/ta-0.10.1-py3-none-any.whl\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from ta==0.10.1) (1.3.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from ta==0.10.1) (1.20.3)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->ta==0.10.1) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->ta==0.10.1) (2021.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->ta==0.10.1) (1.16.0)\nInstalling collected packages: ta\nSuccessfully installed ta-0.10.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"def _calc_spread_return_per_day(df, portfolio_size, toprank_weight_ratio):\n    assert df['Rank'].min() == 0\n    assert df['Rank'].max() == len(df['Rank']) - 1\n    weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n    purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n    short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n    return purchase - short\n\ndef my_calc_spread_return_per_day(df, portfolio_size, toprank_weight_ratio):\n    assert df['Rank'].min() == 0\n    assert df['Rank'].max() == len(df['Rank']) - 1\n    weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n    purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n    short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n    return pd.DataFrame({'long':[purchase],'short':[short],'net':[purchase - short]})\n\ndef calc_spread_return_sharpe(df: pd.DataFrame, portfolio_size: int = 200, toprank_weight_ratio: float = 2) -> float:\n    buf = df.groupby('Date').apply(_calc_spread_return_per_day, portfolio_size, toprank_weight_ratio)\n    sharpe_ratio = buf.mean() / buf.std()\n    return sharpe_ratio","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:12:19.215882Z","iopub.execute_input":"2022-07-03T09:12:19.216352Z","iopub.status.idle":"2022-07-03T09:12:19.229291Z","shell.execute_reply.started":"2022-07-03T09:12:19.216302Z","shell.execute_reply":"2022-07-03T09:12:19.228403Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def analyze_signal(df):\n    # preprocess\n    df.Date = pd.to_datetime(df.Date)\n\n    # portfolio return analysis\n    ret = df.groupby('Date').apply(my_calc_spread_return_per_day, 200, 2)\n    ret = ret.reset_index().set_index('Date') \\\n        .assign(short = lambda x: -1 * x.short)\n\n    # cumulative returns\n    new_plot()\n    ret.long.cumsum().plot(label='long')\n    ret.short.cumsum().plot(label='short')\n    ret.net.cumsum().plot(label='net')\n    plt.legend(bbox_to_anchor=(1.1, 1.05))\n    plt.grid()\n    plt.title('Cumulative Returns')\n    log(f'Mean long returns: {ret.long.mean()}')\n    log(f'Mean short returns: {ret.short.mean()}')\n    log(f'Mean net returns: {ret.net.mean()}')\n\n    # rolling sharpes\n    new_plot()\n    ret.long.rolling(60).apply(lambda s: s.mean()/s.std()).plot(label='long')\n    ret.short.rolling(60).apply(lambda s: s.mean()/s.std()).plot(label='short')\n    ret.net.rolling(60).apply(lambda s: s.mean()/s.std()).plot(label='net')\n    plt.legend(bbox_to_anchor=(1.1, 1.05))\n    plt.grid()\n    plt.title('Rolling Sharpes')\n    log(f'Sharpe of long: {ret.long.mean() / ret.long.std()}')\n    log(f'Sharpe of short: {ret.short.mean() / ret.short.std()}')\n    log(f'Sharpe of net: {ret.net.mean() / ret.net.std()}')\n    \n    # overall sharpe\n    overall_sharpe = calc_spread_return_sharpe(df)\n    last_6m_sharpe = calc_spread_return_sharpe(df.loc[lambda x: x.Date.isin(df.Date.drop_duplicates().tail(120))])\n    last_3m_sharpe = calc_spread_return_sharpe(df.loc[lambda x: x.Date.isin(df.Date.drop_duplicates().tail(60))])\n    log(f'Overall sharpe: {overall_sharpe}')\n    log(f'Last 6m sharpe: {last_6m_sharpe}')\n    log(f'Last 3m sharpe: {last_3m_sharpe}')","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:12:17.943048Z","iopub.execute_input":"2022-07-03T09:12:17.943508Z","iopub.status.idle":"2022-07-03T09:12:17.962979Z","shell.execute_reply.started":"2022-07-03T09:12:17.943458Z","shell.execute_reply":"2022-07-03T09:12:17.962296Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"df_pred_val = []\nfor ver in [11,12,17,19,20,26]:\n    df = pd.read_feather(f'../input/jpx-model-lgbm-v{ver}/df_pred_val')\n    df['ver'] = ver\n    df_pred_val.append(df)\ndf_pred_val = pd.concat(df_pred_val).reset_index(drop=True)","metadata":{"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                 RowId       Date  SecuritiesCode  pred_model  target_train  \\\n0        20210305_1301 2021-03-05            1301   -0.007409           1.0   \n1        20210305_1376 2021-03-05            1376    0.014942           0.0   \n2        20210305_1766 2021-03-05            1766   -0.002871           1.0   \n3        20210305_1810 2021-03-05            1810    0.005535           1.0   \n4        20210305_1822 2021-03-05            1822   -0.016952           0.0   \n...                ...        ...             ...         ...           ...   \n3837269  20220624_9687 2022-06-24            9687    0.506032           0.0   \n3837270  20220624_9733 2022-06-24            9733    0.505941           0.0   \n3837271  20220624_9831 2022-06-24            9831    0.507130           1.0   \n3837272  20220624_9906 2022-06-24            9906    0.502690           1.0   \n3837273  20220624_9955 2022-06-24            9955    0.507777           0.0   \n\n           Target  Rank  rank_pred  rank_true  clust  pred_model_mean  \\\n0        0.011182  1748      349.0      662.0      5         0.007131   \n1       -0.003729   567     1511.0        1.0      5         0.007131   \n2        0.019037  1579      520.0      663.0      5         0.007131   \n3        0.015110  1141      952.0      664.0      5         0.007131   \n4       -0.003866  1914      137.0        2.0      5         0.007131   \n...           ...   ...        ...        ...    ...              ...   \n3837269 -0.014479   828     1213.0      996.0      2         0.505664   \n3837270  0.005545   864     1187.0      997.0      2         0.505664   \n3837271  0.031780   646     1435.0     1995.0      2         0.505664   \n3837272  0.014449  1788      306.0     1996.0      2         0.505664   \n3837273 -0.001288   332     1572.0      998.0      2         0.505664   \n\n         pred_model_demean       std  pred_model_vol_penalty  ver  \n0                -0.014540  0.009959               -0.030106   11  \n1                 0.007811  0.012030                0.015697   11  \n2                -0.010002  0.012702               -0.019928   11  \n3                -0.001596  0.017719               -0.003018   11  \n4                -0.024083  0.011221               -0.048933   11  \n...                    ...       ...                     ...  ...  \n3837269           0.000368  0.008164                0.001681   26  \n3837270           0.000278  0.010462                0.001171   26  \n3837271           0.001466  0.029899                0.004443   26  \n3837272          -0.002974  0.012492               -0.011867   26  \n3837273           0.002113  0.007892                0.009747   26  \n\n[3837274 rows x 15 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RowId</th>\n      <th>Date</th>\n      <th>SecuritiesCode</th>\n      <th>pred_model</th>\n      <th>target_train</th>\n      <th>Target</th>\n      <th>Rank</th>\n      <th>rank_pred</th>\n      <th>rank_true</th>\n      <th>clust</th>\n      <th>pred_model_mean</th>\n      <th>pred_model_demean</th>\n      <th>std</th>\n      <th>pred_model_vol_penalty</th>\n      <th>ver</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20210305_1301</td>\n      <td>2021-03-05</td>\n      <td>1301</td>\n      <td>-0.007409</td>\n      <td>1.0</td>\n      <td>0.011182</td>\n      <td>1748</td>\n      <td>349.0</td>\n      <td>662.0</td>\n      <td>5</td>\n      <td>0.007131</td>\n      <td>-0.014540</td>\n      <td>0.009959</td>\n      <td>-0.030106</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20210305_1376</td>\n      <td>2021-03-05</td>\n      <td>1376</td>\n      <td>0.014942</td>\n      <td>0.0</td>\n      <td>-0.003729</td>\n      <td>567</td>\n      <td>1511.0</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>0.007131</td>\n      <td>0.007811</td>\n      <td>0.012030</td>\n      <td>0.015697</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20210305_1766</td>\n      <td>2021-03-05</td>\n      <td>1766</td>\n      <td>-0.002871</td>\n      <td>1.0</td>\n      <td>0.019037</td>\n      <td>1579</td>\n      <td>520.0</td>\n      <td>663.0</td>\n      <td>5</td>\n      <td>0.007131</td>\n      <td>-0.010002</td>\n      <td>0.012702</td>\n      <td>-0.019928</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20210305_1810</td>\n      <td>2021-03-05</td>\n      <td>1810</td>\n      <td>0.005535</td>\n      <td>1.0</td>\n      <td>0.015110</td>\n      <td>1141</td>\n      <td>952.0</td>\n      <td>664.0</td>\n      <td>5</td>\n      <td>0.007131</td>\n      <td>-0.001596</td>\n      <td>0.017719</td>\n      <td>-0.003018</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20210305_1822</td>\n      <td>2021-03-05</td>\n      <td>1822</td>\n      <td>-0.016952</td>\n      <td>0.0</td>\n      <td>-0.003866</td>\n      <td>1914</td>\n      <td>137.0</td>\n      <td>2.0</td>\n      <td>5</td>\n      <td>0.007131</td>\n      <td>-0.024083</td>\n      <td>0.011221</td>\n      <td>-0.048933</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3837269</th>\n      <td>20220624_9687</td>\n      <td>2022-06-24</td>\n      <td>9687</td>\n      <td>0.506032</td>\n      <td>0.0</td>\n      <td>-0.014479</td>\n      <td>828</td>\n      <td>1213.0</td>\n      <td>996.0</td>\n      <td>2</td>\n      <td>0.505664</td>\n      <td>0.000368</td>\n      <td>0.008164</td>\n      <td>0.001681</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>3837270</th>\n      <td>20220624_9733</td>\n      <td>2022-06-24</td>\n      <td>9733</td>\n      <td>0.505941</td>\n      <td>0.0</td>\n      <td>0.005545</td>\n      <td>864</td>\n      <td>1187.0</td>\n      <td>997.0</td>\n      <td>2</td>\n      <td>0.505664</td>\n      <td>0.000278</td>\n      <td>0.010462</td>\n      <td>0.001171</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>3837271</th>\n      <td>20220624_9831</td>\n      <td>2022-06-24</td>\n      <td>9831</td>\n      <td>0.507130</td>\n      <td>1.0</td>\n      <td>0.031780</td>\n      <td>646</td>\n      <td>1435.0</td>\n      <td>1995.0</td>\n      <td>2</td>\n      <td>0.505664</td>\n      <td>0.001466</td>\n      <td>0.029899</td>\n      <td>0.004443</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>3837272</th>\n      <td>20220624_9906</td>\n      <td>2022-06-24</td>\n      <td>9906</td>\n      <td>0.502690</td>\n      <td>1.0</td>\n      <td>0.014449</td>\n      <td>1788</td>\n      <td>306.0</td>\n      <td>1996.0</td>\n      <td>2</td>\n      <td>0.505664</td>\n      <td>-0.002974</td>\n      <td>0.012492</td>\n      <td>-0.011867</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>3837273</th>\n      <td>20220624_9955</td>\n      <td>2022-06-24</td>\n      <td>9955</td>\n      <td>0.507777</td>\n      <td>0.0</td>\n      <td>-0.001288</td>\n      <td>332</td>\n      <td>1572.0</td>\n      <td>998.0</td>\n      <td>2</td>\n      <td>0.505664</td>\n      <td>0.002113</td>\n      <td>0.007892</td>\n      <td>0.009747</td>\n      <td>26</td>\n    </tr>\n  </tbody>\n</table>\n<p>3837274 rows × 15 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_pred_val['Rank_raw'] = df_pred_val.groupby(['ver','Date']).pred_model.rank(method='first', ascending=False).astype(int) - 1\ndf_pred_val['Rank_demean'] = df_pred_val.groupby(['ver','Date']).pred_model_demean.rank(method='first', ascending=False).astype(int) - 1\ndf_pred_val['Rank_vol_penalty'] = df_pred_val.groupby(['ver','Date']).pred_model_vol_penalty.rank(method='first', ascending=False).astype(int) - 1","metadata":{"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                 RowId       Date  SecuritiesCode  pred_model  target_train  \\\n0        20210305_1301 2021-03-05            1301   -0.007409           1.0   \n1        20210305_1376 2021-03-05            1376    0.014942           0.0   \n2        20210305_1766 2021-03-05            1766   -0.002871           1.0   \n3        20210305_1810 2021-03-05            1810    0.005535           1.0   \n4        20210305_1822 2021-03-05            1822   -0.016952           0.0   \n...                ...        ...             ...         ...           ...   \n3837269  20220624_9687 2022-06-24            9687    0.506032           0.0   \n3837270  20220624_9733 2022-06-24            9733    0.505941           0.0   \n3837271  20220624_9831 2022-06-24            9831    0.507130           1.0   \n3837272  20220624_9906 2022-06-24            9906    0.502690           1.0   \n3837273  20220624_9955 2022-06-24            9955    0.507777           0.0   \n\n           Target  Rank  rank_pred  rank_true  clust  pred_model_mean  \\\n0        0.011182  1748      349.0      662.0      5         0.007131   \n1       -0.003729   567     1511.0        1.0      5         0.007131   \n2        0.019037  1579      520.0      663.0      5         0.007131   \n3        0.015110  1141      952.0      664.0      5         0.007131   \n4       -0.003866  1914      137.0        2.0      5         0.007131   \n...           ...   ...        ...        ...    ...              ...   \n3837269 -0.014479   828     1213.0      996.0      2         0.505664   \n3837270  0.005545   864     1187.0      997.0      2         0.505664   \n3837271  0.031780   646     1435.0     1995.0      2         0.505664   \n3837272  0.014449  1788      306.0     1996.0      2         0.505664   \n3837273 -0.001288   332     1572.0      998.0      2         0.505664   \n\n         pred_model_demean       std  pred_model_vol_penalty  ver  Rank_raw  \\\n0                -0.014540  0.009959               -0.030106   11      1641   \n1                 0.007811  0.012030                0.015697   11       479   \n2                -0.010002  0.012702               -0.019928   11      1470   \n3                -0.001596  0.017719               -0.003018   11      1038   \n4                -0.024083  0.011221               -0.048933   11      1853   \n...                    ...       ...                     ...  ...       ...   \n3837269           0.000368  0.008164                0.001681   26       783   \n3837270           0.000278  0.010462                0.001171   26       809   \n3837271           0.001466  0.029899                0.004443   26       561   \n3837272          -0.002974  0.012492               -0.011867   26      1690   \n3837273           0.002113  0.007892                0.009747   26       424   \n\n         Rank_demean  Rank_vol_penalty  \n0               1704              1748  \n1                597               567  \n2               1554              1579  \n3               1140              1141  \n4               1880              1914  \n...              ...               ...  \n3837269          856               828  \n3837270          874               864  \n3837271          614               646  \n3837272         1734              1788  \n3837273          477               332  \n\n[3837274 rows x 18 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RowId</th>\n      <th>Date</th>\n      <th>SecuritiesCode</th>\n      <th>pred_model</th>\n      <th>target_train</th>\n      <th>Target</th>\n      <th>Rank</th>\n      <th>rank_pred</th>\n      <th>rank_true</th>\n      <th>clust</th>\n      <th>pred_model_mean</th>\n      <th>pred_model_demean</th>\n      <th>std</th>\n      <th>pred_model_vol_penalty</th>\n      <th>ver</th>\n      <th>Rank_raw</th>\n      <th>Rank_demean</th>\n      <th>Rank_vol_penalty</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20210305_1301</td>\n      <td>2021-03-05</td>\n      <td>1301</td>\n      <td>-0.007409</td>\n      <td>1.0</td>\n      <td>0.011182</td>\n      <td>1748</td>\n      <td>349.0</td>\n      <td>662.0</td>\n      <td>5</td>\n      <td>0.007131</td>\n      <td>-0.014540</td>\n      <td>0.009959</td>\n      <td>-0.030106</td>\n      <td>11</td>\n      <td>1641</td>\n      <td>1704</td>\n      <td>1748</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20210305_1376</td>\n      <td>2021-03-05</td>\n      <td>1376</td>\n      <td>0.014942</td>\n      <td>0.0</td>\n      <td>-0.003729</td>\n      <td>567</td>\n      <td>1511.0</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>0.007131</td>\n      <td>0.007811</td>\n      <td>0.012030</td>\n      <td>0.015697</td>\n      <td>11</td>\n      <td>479</td>\n      <td>597</td>\n      <td>567</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20210305_1766</td>\n      <td>2021-03-05</td>\n      <td>1766</td>\n      <td>-0.002871</td>\n      <td>1.0</td>\n      <td>0.019037</td>\n      <td>1579</td>\n      <td>520.0</td>\n      <td>663.0</td>\n      <td>5</td>\n      <td>0.007131</td>\n      <td>-0.010002</td>\n      <td>0.012702</td>\n      <td>-0.019928</td>\n      <td>11</td>\n      <td>1470</td>\n      <td>1554</td>\n      <td>1579</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20210305_1810</td>\n      <td>2021-03-05</td>\n      <td>1810</td>\n      <td>0.005535</td>\n      <td>1.0</td>\n      <td>0.015110</td>\n      <td>1141</td>\n      <td>952.0</td>\n      <td>664.0</td>\n      <td>5</td>\n      <td>0.007131</td>\n      <td>-0.001596</td>\n      <td>0.017719</td>\n      <td>-0.003018</td>\n      <td>11</td>\n      <td>1038</td>\n      <td>1140</td>\n      <td>1141</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20210305_1822</td>\n      <td>2021-03-05</td>\n      <td>1822</td>\n      <td>-0.016952</td>\n      <td>0.0</td>\n      <td>-0.003866</td>\n      <td>1914</td>\n      <td>137.0</td>\n      <td>2.0</td>\n      <td>5</td>\n      <td>0.007131</td>\n      <td>-0.024083</td>\n      <td>0.011221</td>\n      <td>-0.048933</td>\n      <td>11</td>\n      <td>1853</td>\n      <td>1880</td>\n      <td>1914</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3837269</th>\n      <td>20220624_9687</td>\n      <td>2022-06-24</td>\n      <td>9687</td>\n      <td>0.506032</td>\n      <td>0.0</td>\n      <td>-0.014479</td>\n      <td>828</td>\n      <td>1213.0</td>\n      <td>996.0</td>\n      <td>2</td>\n      <td>0.505664</td>\n      <td>0.000368</td>\n      <td>0.008164</td>\n      <td>0.001681</td>\n      <td>26</td>\n      <td>783</td>\n      <td>856</td>\n      <td>828</td>\n    </tr>\n    <tr>\n      <th>3837270</th>\n      <td>20220624_9733</td>\n      <td>2022-06-24</td>\n      <td>9733</td>\n      <td>0.505941</td>\n      <td>0.0</td>\n      <td>0.005545</td>\n      <td>864</td>\n      <td>1187.0</td>\n      <td>997.0</td>\n      <td>2</td>\n      <td>0.505664</td>\n      <td>0.000278</td>\n      <td>0.010462</td>\n      <td>0.001171</td>\n      <td>26</td>\n      <td>809</td>\n      <td>874</td>\n      <td>864</td>\n    </tr>\n    <tr>\n      <th>3837271</th>\n      <td>20220624_9831</td>\n      <td>2022-06-24</td>\n      <td>9831</td>\n      <td>0.507130</td>\n      <td>1.0</td>\n      <td>0.031780</td>\n      <td>646</td>\n      <td>1435.0</td>\n      <td>1995.0</td>\n      <td>2</td>\n      <td>0.505664</td>\n      <td>0.001466</td>\n      <td>0.029899</td>\n      <td>0.004443</td>\n      <td>26</td>\n      <td>561</td>\n      <td>614</td>\n      <td>646</td>\n    </tr>\n    <tr>\n      <th>3837272</th>\n      <td>20220624_9906</td>\n      <td>2022-06-24</td>\n      <td>9906</td>\n      <td>0.502690</td>\n      <td>1.0</td>\n      <td>0.014449</td>\n      <td>1788</td>\n      <td>306.0</td>\n      <td>1996.0</td>\n      <td>2</td>\n      <td>0.505664</td>\n      <td>-0.002974</td>\n      <td>0.012492</td>\n      <td>-0.011867</td>\n      <td>26</td>\n      <td>1690</td>\n      <td>1734</td>\n      <td>1788</td>\n    </tr>\n    <tr>\n      <th>3837273</th>\n      <td>20220624_9955</td>\n      <td>2022-06-24</td>\n      <td>9955</td>\n      <td>0.507777</td>\n      <td>0.0</td>\n      <td>-0.001288</td>\n      <td>332</td>\n      <td>1572.0</td>\n      <td>998.0</td>\n      <td>2</td>\n      <td>0.505664</td>\n      <td>0.002113</td>\n      <td>0.007892</td>\n      <td>0.009747</td>\n      <td>26</td>\n      <td>424</td>\n      <td>477</td>\n      <td>332</td>\n    </tr>\n  </tbody>\n</table>\n<p>3837274 rows × 18 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def cal_avg_sharpe(df_pred_val, col, ver1, ver2):\n    # df_pred_val, col, ver1, ver2 = df_pred_val, 'Rank_raw', 11, 26\n    df1 = df_pred_val.loc[lambda x: x.ver==ver1].assign(Rank=lambda x: x[col]).loc[:, ['RowId','Date','SecuritiesCode','Rank','Target']].reset_index(drop=True)\n    df2 = df_pred_val.loc[lambda x: x.ver==ver2].assign(Rank=lambda x: x[col]).loc[:, ['RowId','Date','SecuritiesCode','Rank','Target']].reset_index(drop=True)\n    df = pd.concat([df1, df2]).groupby(['RowId','Date','SecuritiesCode'])[['Rank','Target']].mean().reset_index()\n    df['Rank'] = df.groupby('Date').Rank.rank(method='first', ascending=True).astype(int) - 1\n    sharpe = calc_spread_return_sharpe(df)\n    return sharpe","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:22:57.707785Z","iopub.execute_input":"2022-07-03T09:22:57.708321Z","iopub.status.idle":"2022-07-03T09:22:57.717738Z","shell.execute_reply.started":"2022-07-03T09:22:57.708288Z","shell.execute_reply":"2022-07-03T09:22:57.717163Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"ver_list = df_pred_val.ver.unique().tolist()\ntup_list = list(itertools.product(ver_list, ver_list))\ntup_list = list(set([tuple(sorted(list(x))) for x in tup_list]))\n\nresult = []\nfor col in ['Rank_raw','Rank_demean','Rank_vol_penalty']:\n    for ver1, ver2 in tup_list:\n        sharpe = cal_avg_sharpe(df_pred_val, col, ver1, ver2)\n        result.append((col, ver1, ver2, sharpe))\nresult = pd.DataFrame(result, columns=['col','ver1','ver2','sharpe'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in ['Rank_raw','Rank_demean','Rank_vol_penalty']:\n    print(col)\n    display(result.loc[lambda x: (x.col==col) & (x.ver1==x.ver2)].sort_values('sharpe', ascending=False))\n    display(result.loc[lambda x: (x.col==col) & (x.ver1!=x.ver2)].sort_values('sharpe', ascending=False))\n    display(result.loc[lambda x: x.col==col].pivot(index='ver1', columns='ver2', values='sharpe'))","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:29:17.283245Z","iopub.execute_input":"2022-07-03T09:29:17.284072Z","iopub.status.idle":"2022-07-03T09:29:17.383224Z","shell.execute_reply.started":"2022-07-03T09:29:17.284023Z","shell.execute_reply":"2022-07-03T09:29:17.382054Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Rank_raw\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"         col  ver1  ver2    sharpe\n4   Rank_raw    20    20  0.191040\n11  Rank_raw    26    26  0.177160\n20  Rank_raw    17    17  0.159819\n1   Rank_raw    19    19  0.153882\n0   Rank_raw    11    11  0.149709\n3   Rank_raw    12    12  0.145860","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>col</th>\n      <th>ver1</th>\n      <th>ver2</th>\n      <th>sharpe</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>Rank_raw</td>\n      <td>20</td>\n      <td>20</td>\n      <td>0.191040</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Rank_raw</td>\n      <td>26</td>\n      <td>26</td>\n      <td>0.177160</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Rank_raw</td>\n      <td>17</td>\n      <td>17</td>\n      <td>0.159819</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Rank_raw</td>\n      <td>19</td>\n      <td>19</td>\n      <td>0.153882</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Rank_raw</td>\n      <td>11</td>\n      <td>11</td>\n      <td>0.149709</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Rank_raw</td>\n      <td>12</td>\n      <td>12</td>\n      <td>0.145860</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"         col  ver1  ver2    sharpe\n5   Rank_raw    17    20  0.240142\n8   Rank_raw    12    20  0.225363\n13  Rank_raw    19    20  0.218982\n7   Rank_raw    20    26  0.212879\n17  Rank_raw    12    19  0.204045\n19  Rank_raw    17    26  0.201798\n10  Rank_raw    17    19  0.199867\n12  Rank_raw    11    26  0.197669\n2   Rank_raw    19    26  0.195100\n18  Rank_raw    11    20  0.190196\n16  Rank_raw    12    26  0.185319\n15  Rank_raw    11    17  0.172554\n6   Rank_raw    11    19  0.162920\n9   Rank_raw    12    17  0.155784\n14  Rank_raw    11    12  0.142546","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>col</th>\n      <th>ver1</th>\n      <th>ver2</th>\n      <th>sharpe</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>Rank_raw</td>\n      <td>17</td>\n      <td>20</td>\n      <td>0.240142</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Rank_raw</td>\n      <td>12</td>\n      <td>20</td>\n      <td>0.225363</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Rank_raw</td>\n      <td>19</td>\n      <td>20</td>\n      <td>0.218982</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Rank_raw</td>\n      <td>20</td>\n      <td>26</td>\n      <td>0.212879</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Rank_raw</td>\n      <td>12</td>\n      <td>19</td>\n      <td>0.204045</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Rank_raw</td>\n      <td>17</td>\n      <td>26</td>\n      <td>0.201798</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Rank_raw</td>\n      <td>17</td>\n      <td>19</td>\n      <td>0.199867</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Rank_raw</td>\n      <td>11</td>\n      <td>26</td>\n      <td>0.197669</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Rank_raw</td>\n      <td>19</td>\n      <td>26</td>\n      <td>0.195100</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Rank_raw</td>\n      <td>11</td>\n      <td>20</td>\n      <td>0.190196</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Rank_raw</td>\n      <td>12</td>\n      <td>26</td>\n      <td>0.185319</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Rank_raw</td>\n      <td>11</td>\n      <td>17</td>\n      <td>0.172554</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Rank_raw</td>\n      <td>11</td>\n      <td>19</td>\n      <td>0.162920</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Rank_raw</td>\n      <td>12</td>\n      <td>17</td>\n      <td>0.155784</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Rank_raw</td>\n      <td>11</td>\n      <td>12</td>\n      <td>0.142546</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ver2        11        12        17        19        20        26\nver1                                                            \n11    0.149709  0.142546  0.172554  0.162920  0.190196  0.197669\n12         NaN  0.145860  0.155784  0.204045  0.225363  0.185319\n17         NaN       NaN  0.159819  0.199867  0.240142  0.201798\n19         NaN       NaN       NaN  0.153882  0.218982  0.195100\n20         NaN       NaN       NaN       NaN  0.191040  0.212879\n26         NaN       NaN       NaN       NaN       NaN  0.177160","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>ver2</th>\n      <th>11</th>\n      <th>12</th>\n      <th>17</th>\n      <th>19</th>\n      <th>20</th>\n      <th>26</th>\n    </tr>\n    <tr>\n      <th>ver1</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <td>0.149709</td>\n      <td>0.142546</td>\n      <td>0.172554</td>\n      <td>0.162920</td>\n      <td>0.190196</td>\n      <td>0.197669</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>NaN</td>\n      <td>0.145860</td>\n      <td>0.155784</td>\n      <td>0.204045</td>\n      <td>0.225363</td>\n      <td>0.185319</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.159819</td>\n      <td>0.199867</td>\n      <td>0.240142</td>\n      <td>0.201798</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.153882</td>\n      <td>0.218982</td>\n      <td>0.195100</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.191040</td>\n      <td>0.212879</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.177160</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Rank_demean\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"            col  ver1  ver2    sharpe\n25  Rank_demean    20    20  0.172167\n32  Rank_demean    26    26  0.169205\n41  Rank_demean    17    17  0.142740\n22  Rank_demean    19    19  0.139433\n21  Rank_demean    11    11  0.139320\n24  Rank_demean    12    12  0.129019","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>col</th>\n      <th>ver1</th>\n      <th>ver2</th>\n      <th>sharpe</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>25</th>\n      <td>Rank_demean</td>\n      <td>20</td>\n      <td>20</td>\n      <td>0.172167</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Rank_demean</td>\n      <td>26</td>\n      <td>26</td>\n      <td>0.169205</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>Rank_demean</td>\n      <td>17</td>\n      <td>17</td>\n      <td>0.142740</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Rank_demean</td>\n      <td>19</td>\n      <td>19</td>\n      <td>0.139433</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Rank_demean</td>\n      <td>11</td>\n      <td>11</td>\n      <td>0.139320</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Rank_demean</td>\n      <td>12</td>\n      <td>12</td>\n      <td>0.129019</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"            col  ver1  ver2    sharpe\n26  Rank_demean    17    20  0.214073\n34  Rank_demean    19    20  0.202690\n23  Rank_demean    19    26  0.196613\n31  Rank_demean    17    19  0.196118\n28  Rank_demean    20    26  0.191828\n29  Rank_demean    12    20  0.191726\n40  Rank_demean    17    26  0.187498\n38  Rank_demean    12    19  0.185075\n33  Rank_demean    11    26  0.183449\n39  Rank_demean    11    20  0.171905\n36  Rank_demean    11    17  0.155666\n27  Rank_demean    11    19  0.150862\n37  Rank_demean    12    26  0.143591\n30  Rank_demean    12    17  0.143035\n35  Rank_demean    11    12  0.126569","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>col</th>\n      <th>ver1</th>\n      <th>ver2</th>\n      <th>sharpe</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>26</th>\n      <td>Rank_demean</td>\n      <td>17</td>\n      <td>20</td>\n      <td>0.214073</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Rank_demean</td>\n      <td>19</td>\n      <td>20</td>\n      <td>0.202690</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Rank_demean</td>\n      <td>19</td>\n      <td>26</td>\n      <td>0.196613</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Rank_demean</td>\n      <td>17</td>\n      <td>19</td>\n      <td>0.196118</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Rank_demean</td>\n      <td>20</td>\n      <td>26</td>\n      <td>0.191828</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Rank_demean</td>\n      <td>12</td>\n      <td>20</td>\n      <td>0.191726</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>Rank_demean</td>\n      <td>17</td>\n      <td>26</td>\n      <td>0.187498</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>Rank_demean</td>\n      <td>12</td>\n      <td>19</td>\n      <td>0.185075</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Rank_demean</td>\n      <td>11</td>\n      <td>26</td>\n      <td>0.183449</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>Rank_demean</td>\n      <td>11</td>\n      <td>20</td>\n      <td>0.171905</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>Rank_demean</td>\n      <td>11</td>\n      <td>17</td>\n      <td>0.155666</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Rank_demean</td>\n      <td>11</td>\n      <td>19</td>\n      <td>0.150862</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Rank_demean</td>\n      <td>12</td>\n      <td>26</td>\n      <td>0.143591</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Rank_demean</td>\n      <td>12</td>\n      <td>17</td>\n      <td>0.143035</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Rank_demean</td>\n      <td>11</td>\n      <td>12</td>\n      <td>0.126569</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ver2       11        12        17        19        20        26\nver1                                                           \n11    0.13932  0.126569  0.155666  0.150862  0.171905  0.183449\n12        NaN  0.129019  0.143035  0.185075  0.191726  0.143591\n17        NaN       NaN  0.142740  0.196118  0.214073  0.187498\n19        NaN       NaN       NaN  0.139433  0.202690  0.196613\n20        NaN       NaN       NaN       NaN  0.172167  0.191828\n26        NaN       NaN       NaN       NaN       NaN  0.169205","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>ver2</th>\n      <th>11</th>\n      <th>12</th>\n      <th>17</th>\n      <th>19</th>\n      <th>20</th>\n      <th>26</th>\n    </tr>\n    <tr>\n      <th>ver1</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <td>0.13932</td>\n      <td>0.126569</td>\n      <td>0.155666</td>\n      <td>0.150862</td>\n      <td>0.171905</td>\n      <td>0.183449</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>NaN</td>\n      <td>0.129019</td>\n      <td>0.143035</td>\n      <td>0.185075</td>\n      <td>0.191726</td>\n      <td>0.143591</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.142740</td>\n      <td>0.196118</td>\n      <td>0.214073</td>\n      <td>0.187498</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.139433</td>\n      <td>0.202690</td>\n      <td>0.196613</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.172167</td>\n      <td>0.191828</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.169205</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Rank_vol_penalty\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                 col  ver1  ver2    sharpe\n43  Rank_vol_penalty    19    19  0.210763\n46  Rank_vol_penalty    20    20  0.186588\n62  Rank_vol_penalty    17    17  0.182802\n53  Rank_vol_penalty    26    26  0.178678\n45  Rank_vol_penalty    12    12  0.166620\n42  Rank_vol_penalty    11    11  0.139996","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>col</th>\n      <th>ver1</th>\n      <th>ver2</th>\n      <th>sharpe</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>43</th>\n      <td>Rank_vol_penalty</td>\n      <td>19</td>\n      <td>19</td>\n      <td>0.210763</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>Rank_vol_penalty</td>\n      <td>20</td>\n      <td>20</td>\n      <td>0.186588</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>Rank_vol_penalty</td>\n      <td>17</td>\n      <td>17</td>\n      <td>0.182802</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>Rank_vol_penalty</td>\n      <td>26</td>\n      <td>26</td>\n      <td>0.178678</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>Rank_vol_penalty</td>\n      <td>12</td>\n      <td>12</td>\n      <td>0.166620</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>Rank_vol_penalty</td>\n      <td>11</td>\n      <td>11</td>\n      <td>0.139996</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"                 col  ver1  ver2    sharpe\n55  Rank_vol_penalty    19    20  0.220244\n49  Rank_vol_penalty    20    26  0.197043\n51  Rank_vol_penalty    12    17  0.195422\n47  Rank_vol_penalty    17    20  0.194639\n59  Rank_vol_penalty    12    19  0.192236\n52  Rank_vol_penalty    17    19  0.189215\n54  Rank_vol_penalty    11    26  0.188484\n50  Rank_vol_penalty    12    20  0.181011\n44  Rank_vol_penalty    19    26  0.174965\n60  Rank_vol_penalty    11    20  0.165603\n48  Rank_vol_penalty    11    19  0.159324\n61  Rank_vol_penalty    17    26  0.131934\n56  Rank_vol_penalty    11    12  0.126037\n57  Rank_vol_penalty    11    17  0.122570\n58  Rank_vol_penalty    12    26  0.122198","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>col</th>\n      <th>ver1</th>\n      <th>ver2</th>\n      <th>sharpe</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>55</th>\n      <td>Rank_vol_penalty</td>\n      <td>19</td>\n      <td>20</td>\n      <td>0.220244</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>Rank_vol_penalty</td>\n      <td>20</td>\n      <td>26</td>\n      <td>0.197043</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>Rank_vol_penalty</td>\n      <td>12</td>\n      <td>17</td>\n      <td>0.195422</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>Rank_vol_penalty</td>\n      <td>17</td>\n      <td>20</td>\n      <td>0.194639</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>Rank_vol_penalty</td>\n      <td>12</td>\n      <td>19</td>\n      <td>0.192236</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>Rank_vol_penalty</td>\n      <td>17</td>\n      <td>19</td>\n      <td>0.189215</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>Rank_vol_penalty</td>\n      <td>11</td>\n      <td>26</td>\n      <td>0.188484</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>Rank_vol_penalty</td>\n      <td>12</td>\n      <td>20</td>\n      <td>0.181011</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>Rank_vol_penalty</td>\n      <td>19</td>\n      <td>26</td>\n      <td>0.174965</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>Rank_vol_penalty</td>\n      <td>11</td>\n      <td>20</td>\n      <td>0.165603</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>Rank_vol_penalty</td>\n      <td>11</td>\n      <td>19</td>\n      <td>0.159324</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>Rank_vol_penalty</td>\n      <td>17</td>\n      <td>26</td>\n      <td>0.131934</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>Rank_vol_penalty</td>\n      <td>11</td>\n      <td>12</td>\n      <td>0.126037</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>Rank_vol_penalty</td>\n      <td>11</td>\n      <td>17</td>\n      <td>0.122570</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>Rank_vol_penalty</td>\n      <td>12</td>\n      <td>26</td>\n      <td>0.122198</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ver2        11        12        17        19        20        26\nver1                                                            \n11    0.139996  0.126037  0.122570  0.159324  0.165603  0.188484\n12         NaN  0.166620  0.195422  0.192236  0.181011  0.122198\n17         NaN       NaN  0.182802  0.189215  0.194639  0.131934\n19         NaN       NaN       NaN  0.210763  0.220244  0.174965\n20         NaN       NaN       NaN       NaN  0.186588  0.197043\n26         NaN       NaN       NaN       NaN       NaN  0.178678","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>ver2</th>\n      <th>11</th>\n      <th>12</th>\n      <th>17</th>\n      <th>19</th>\n      <th>20</th>\n      <th>26</th>\n    </tr>\n    <tr>\n      <th>ver1</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <td>0.139996</td>\n      <td>0.126037</td>\n      <td>0.122570</td>\n      <td>0.159324</td>\n      <td>0.165603</td>\n      <td>0.188484</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>NaN</td>\n      <td>0.166620</td>\n      <td>0.195422</td>\n      <td>0.192236</td>\n      <td>0.181011</td>\n      <td>0.122198</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.182802</td>\n      <td>0.189215</td>\n      <td>0.194639</td>\n      <td>0.131934</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.210763</td>\n      <td>0.220244</td>\n      <td>0.174965</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.186588</td>\n      <td>0.197043</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.178678</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_pred_val.groupby('RowId').size().value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T08:49:43.633573Z","iopub.execute_input":"2022-07-03T08:49:43.634532Z","iopub.status.idle":"2022-07-03T08:49:45.379244Z","shell.execute_reply.started":"2022-07-03T08:49:43.634492Z","shell.execute_reply":"2022-07-03T08:49:45.378371Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"6    639499\n1       280\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# general params\nFE = 'orig'\nMODEL = 'clf3'\nFE_PATH = '../input/jpx-feature-engineering-v15'\nMODEL_PATH = '../input/jpx-model-lgbm-v20'\nJPX_PATH = '../input/jpx-tokyo-stock-exchange-prediction'\nEXPORT = True","metadata":{"execution":{"iopub.status.busy":"2022-07-02T11:31:52.313693Z","iopub.execute_input":"2022-07-02T11:31:52.313976Z","iopub.status.idle":"2022-07-02T11:31:52.319261Z","shell.execute_reply.started":"2022-07-02T11:31:52.313941Z","shell.execute_reply":"2022-07-02T11:31:52.318346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nFE Parameters\n'''\nSEED = 0\nLAGS = {'1d':1, '3d':3, '1w':5, '1m':20, '3m':20*3, '6m':20*6, '12m':20*12}\nMAX_DAYS_LAG = max(list(LAGS.values()))\nWIN_SIZE = 500","metadata":{"_uuid":"c3cfb2dc-8437-441f-b2c0-88b3d4a77281","_cell_guid":"c0f0bfa1-3dea-43a3-b2f1-8a2c268d6339","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-02T11:31:52.320925Z","iopub.execute_input":"2022-07-02T11:31:52.321256Z","iopub.status.idle":"2022-07-02T11:31:52.334729Z","shell.execute_reply.started":"2022-07-02T11:31:52.321211Z","shell.execute_reply":"2022-07-02T11:31:52.333717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nModel Params\n'''\n# basic\nSEED = 0\nSEEDS = [1,2,3,4,5]\n\n# feature composition\nDROP_MARKET_FEATS = False\n\n# PCA\nRUN_PCA = True\nPCA_SPLIT = False\n\n# target definition\nRANK_ASCENDING = False # set this to False if model prediction is same direction of Target\nTARGET_POW = 0\n\n# data split\nN_FOLD = 5\n\n# final features\nSELECTED_FEATS = 'pc35, pc27, pc12, pc8, pc16, pc6, pc4'.split(', ')\n\n# optimization\nCLUSTER_DEMEAN = True\nCLUST_N_DAY = 60\nVOL_PENALTY = True\nVOL_N_DAY = 60\nVOL_POW = 1.5789473684210527","metadata":{"execution":{"iopub.status.busy":"2022-07-02T11:31:52.337072Z","iopub.execute_input":"2022-07-02T11:31:52.337386Z","iopub.status.idle":"2022-07-02T11:31:52.347054Z","shell.execute_reply.started":"2022-07-02T11:31:52.33734Z","shell.execute_reply":"2022-07-02T11:31:52.346223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"class JPXData:\n    def __init__(self, window_size, df_names):\n        self.size = 0\n        self.window_size = window_size\n        self.df_names = df_names\n        self.num_df = len(df_names)\n        self.data = {df_name : pd.DataFrame() for df_name in df_names}\n        self.row_counts = {df_name : [] for df_name in df_names}\n        self.dates = []\n        self.first_date, self.last_date = None, None\n        self.features = []\n        self.curr_features = None\n        self.n_day_hist = 0\n        self.init_folders()\n        \n    def init_folders(self):\n        shutil.rmtree(path='./features', ignore_errors=True)\n        os.mkdir('./features')\n        \n    def append_data(self):\n        self.features.append(self.curr_features)\n        self.n_day_hist += 1\n        \n    def archive_data(self):\n        save_pkl(self.features, f'./features/features_{self.n_day_hist}')\n        self.clear_hist()\n        \n    def clear_hist(self):\n        self.features = []\n        \n    def push_forward(self, new_data, append, last):\n        # assign names to new data assuming the same as df_names\n        new_data = dict(zip(self.df_names, new_data))\n        # case when no enough data\n        if self.size < self.window_size:\n            for df_name in self.df_names:\n                self.data[df_name] = pd.concat([self.data[df_name], new_data[df_name]]).reset_index(drop=True)\n                self.row_counts[df_name] = self.row_counts[df_name] + [new_data[df_name].shape[0]]\n            self.dates = self.dates + [new_data[self.df_names[0]].Date.iloc[0]] \n            self.size += 1\n        # general case (shift by 1 day)\n        else:\n            for df_name in self.df_names:\n                self.data[df_name] = pd.concat([self.data[df_name].iloc[self.row_counts[df_name][0]:], new_data[df_name]]).reset_index(drop=True)\n                self.row_counts[df_name] = self.row_counts[df_name][1:] + [new_data[df_name].shape[0]]\n            self.dates = self.dates[1:] + [new_data[self.df_names[0]].Date.iloc[0]]  \n        # update date range\n        self.first_date, self.last_date = self.dates[0], self.dates[-1]\n        # generate features\n        if self.size == self.window_size:\n            self.curr_features = get_features(self.data)\n            if append==True:\n                self.append_data()\n                if (self.n_day_hist%20 == 0 and self.n_day_hist > 0) or last==True:\n                    self.archive_data()\n        log(f'Pushed to latest date: {self.last_date}')","metadata":{"_uuid":"54a20792-c5bc-4ee2-8162-07364e311d9c","_cell_guid":"6a3c94c5-9152-4477-9b79-dec0b881fd0e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-02T11:31:52.348489Z","iopub.execute_input":"2022-07-02T11:31:52.34875Z","iopub.status.idle":"2022-07-02T11:31:52.368355Z","shell.execute_reply.started":"2022-07-02T11:31:52.348716Z","shell.execute_reply":"2022-07-02T11:31:52.367329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def standard_dist(s, lag):\n    tail_data = s.tail(LAGS[lag])\n    return (s.iloc[-1] - tail_data.mean()) / tail_data.std()\n\ndef ma_pctg_ch(s, lag):\n    return s.iloc[-1] / s.tail(LAGS[lag]).mean() - 1\n\ndef sharpe(s, lag):\n    tail_data = s.tail(LAGS[lag])\n    std = tail_data.std()\n    if std > 0:\n        sharpe_ratio = tail_data.mean() / tail_data.std()\n    else:\n        sharpe_ratio = 0\n    return sharpe_ratio\n\ndef gen_ta_feats(df, n_day_ma, n_day_scale):\n    # preprocess\n    df = df \\\n        .sort_values(['SecuritiesCode','Date']) \\\n        .groupby('SecuritiesCode') \\\n        .tail(n_day_ma + n_day_scale) \\\n        .loc[:, ['SecuritiesCode','Open','High','Low','Close','Volume']] \\\n        .reset_index(drop=True)\n    # gen TA feats\n    df = ta.add_all_ta_features(df, \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", fillna=False) \\\n        .drop(['Open','High','Low','Close','Volume'], axis=1)\n    ta_cols = df.columns.tolist()[1:]\n    ta_cols = [c for c in ta_cols if c not in ['volatility_atr',\n                                                 'trend_adx',\n                                                 'trend_adx_pos',\n                                                 'trend_adx_neg',\n                                                 'trend_psar_up',\n                                                 'trend_psar_down',\n                                                 'momentum_kama']]\n    ta_cols = ['volume_obv',\n                 'volume_cmf',\n                 'volume_fi',\n                 'volume_em',\n                 'volume_sma_em',\n                 'volume_vpt',\n                 'volume_mfi',\n                 'volume_nvi',\n                 'volatility_bbw',\n                 'volatility_bbhi',\n                 'volatility_bbli',\n                 'volatility_kcw',\n                 'volatility_kcp',\n                 'volatility_kchi',\n                 'volatility_kcli',\n                 'volatility_ui',\n                 'trend_macd_signal',\n                 'trend_macd_diff',\n                 'trend_vortex_ind_pos',\n                 'trend_vortex_ind_neg',\n                 'trend_mass_index',\n                 'trend_dpo',\n                 'trend_kst',\n                 'trend_kst_diff',\n                 'trend_ichimoku_conv',\n                 'trend_stc',\n                 'trend_cci',\n                 'trend_visual_ichimoku_b',\n                 'trend_aroon_up',\n                 'trend_aroon_down',\n                 'trend_psar_up_indicator',\n                 'trend_psar_down_indicator',\n                 'momentum_rsi',\n                 'momentum_stoch_rsi_d',\n                 'momentum_uo',\n                 'momentum_wr',\n                 'momentum_ao',\n                 'momentum_roc',\n                 'momentum_ppo',\n                 'momentum_ppo_hist',\n                 'momentum_pvo',\n                 'momentum_pvo_hist',\n                 'others_dlr']\n    df = df[['SecuritiesCode'] + ta_cols]\n    # scale by mean\n    mean = df \\\n        .groupby('SecuritiesCode') \\\n        .tail(n_day_scale)[ta_cols] \\\n        .abs() \\\n        .mean()\n    for c in ta_cols:\n        df[c] = df[c] / mean[c]\n    # take last row as features\n    df = df.groupby('SecuritiesCode').tail(1)\n    return df","metadata":{"_uuid":"c4fccf97-02d7-4f36-a5fa-53efcfd2edc6","_cell_guid":"ae8fcff3-07c3-4ef5-ade3-61d6dc34243b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-02T11:31:52.369812Z","iopub.execute_input":"2022-07-02T11:31:52.370042Z","iopub.status.idle":"2022-07-02T11:31:52.389284Z","shell.execute_reply.started":"2022-07-02T11:31:52.370014Z","shell.execute_reply":"2022-07-02T11:31:52.388265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nif FE=='orig':\n    def get_features(data):\n        df_prices, df_sec_prices, df_fins, df_opts, df_trades = tuple(data.values())\n\n        # base table\n        features = df_prices \\\n            .loc[lambda x: x.Date==x.Date.iloc[-1]] \\\n            .loc[:, ['RowId','Date','SecuritiesCode']] \\\n            .drop_duplicates(subset='RowId') \\\n            .reset_index(drop=True)\n\n        '''\n        Major stock prices features\n        '''\n        # precalculate new columns\n        cols = [c for c in df_prices.columns.tolist()[3:] if c!='ExpectedDividend']\n        df_prices[cols] = df_prices.groupby('SecuritiesCode')[cols].ffill()\n        df_prices['ret'] = df_prices.groupby('SecuritiesCode').Close.pct_change()\n        ret_mkt = df_prices.groupby('Date').ret.mean()\n        var_mkt = (ret_mkt**2).tail(LAGS['12m']).sum()\n        df_prices['ret_mkt'] = df_prices.Date.map(ret_mkt)\n        df_prices['spread'] = df_prices['High'] - df_prices['Low']\n        df_prices['div_ratio'] = df_prices['ExpectedDividend'].fillna(0) / df_prices['Close']\n        df_prices['dollar_traded'] = np.log(df_prices.Volume * (df_prices.Open + df_prices.Close)/2 + 1)\n        df_prices['RS_sqrt_vol'] = np.sqrt(np.log(df_prices['High']/df_prices['Close'])*np.log(df_prices['High']/df_prices['Open']) + np.log(df_prices['Low']/df_prices['Close'])*np.log(df_prices['Low']/df_prices['Open']))\n        df_prices['num_div'] = df_prices.groupby('SecuritiesCode').ExpectedDividend.apply(lambda s: s.notnull().astype(int).cumsum())\n        df_prices['first_div'] = ((df_prices.num_div==1) & (df_prices.num_div.shift(1)==0)).astype(int)\n        # previous day return\n        features['ret'] = features.SecuritiesCode.map(df_prices.groupby('SecuritiesCode').ret.last())\n        # Change in Close price\n        for lag in ['3d','1w']:\n            features[f'price_ma_pctg_ch_{lag}'] = features.SecuritiesCode.map(df_prices.groupby('SecuritiesCode').Close.apply(lambda s: ma_pctg_ch(s, lag)))\n        for lag in ['1m','3m','6m','12m']:\n            features[f'price_standard_dist_{lag}'] = features.SecuritiesCode.map(df_prices.groupby('SecuritiesCode').Close.apply(lambda s: standard_dist(s, lag)))\n        # Change in volume\n        for lag in ['3d','1w']:\n            features[f'volume_ma_pctg_ch_{lag}'] = features.SecuritiesCode.map(df_prices.groupby('SecuritiesCode').Volume.apply(lambda s: ma_pctg_ch(s, lag)))\n        for lag in ['1m','3m','6m','12m']:\n            features[f'volume_standard_dist_{lag}'] = features.SecuritiesCode.map(df_prices.groupby('SecuritiesCode').Volume.apply(lambda s: standard_dist(s, lag)))\n        # daily spread\n        for lag in ['3d','1w']:\n            features[f'spread_ma_pctg_ch_{lag}'] = features.SecuritiesCode.map(df_prices.groupby('SecuritiesCode').spread.apply(lambda s: ma_pctg_ch(s, lag)))\n        for lag in ['1m']:\n            features[f'spread_standard_dist_{lag}'] = features.SecuritiesCode.map(df_prices.groupby('SecuritiesCode').spread.apply(lambda s: standard_dist(s, lag)))\n        # volatility\n        for lag in ['1w','1m','3m','12m']:\n            features[f'volatility_{lag}'] = features.SecuritiesCode.map(df_prices.groupby('SecuritiesCode').ret.apply(lambda s: s.tail(LAGS[lag]).std())) \n        # change in volatility\n        features['volatility_diff'] = features['volatility_1w'] - features['volatility_1m']\n        # market return and volatility\n        for lag in ['3d','1w','1m','3m']:\n            features[f'ret_mkt_{lag}'] = ret_mkt.tail(LAGS[lag]).sum()\n            features[f'vol_mkt_{lag}'] = ret_mkt.tail(LAGS[lag]).std()\n        # beta\n        df_prices['beta'] = df_prices.SecuritiesCode.map(df_prices.groupby('SecuritiesCode').apply(lambda df: (df.set_index('Date').ret * ret_mkt).tail(LAGS['12m']).sum() / var_mkt))\n        features['beta'] = features.SecuritiesCode.map(df_prices.groupby('SecuritiesCode')['beta'].last())\n        # excess return\n        df_prices['exret'] = df_prices['ret'] - df_prices['beta'] * df_prices['ret_mkt']\n        for lag in ['3d','1w','1m','3m']:\n            features[f'exret_{lag}'] = features.SecuritiesCode.map(df_prices.groupby('SecuritiesCode')['exret'].apply(lambda s: s.tail(LAGS[lag]).sum()))\n        # div ratio\n        features['div_ratio'] = features.SecuritiesCode.map(df_prices.groupby('SecuritiesCode').apply(lambda df: df.ExpectedDividend.fillna(0).iloc[-1] / df.Close.tail(LAGS['1m']).mean()))\n        # change in dollar value traded\n        for lag in ['1w','1m']:\n            features[f'dollar_standard_dist_{lag}'] = features.SecuritiesCode.map(df_prices.groupby('SecuritiesCode').dollar_traded.apply(lambda s: standard_dist(s, lag)))\n        # RS_sqrt_vol\n        features['RS_sqrt_vol'] = features.SecuritiesCode.map(df_prices.groupby('SecuritiesCode').RS_sqrt_vol.last())\n        # sharpe\n        for lag in ['1m','3m']:\n            features[f'sharpe_{lag}'] = features.SecuritiesCode.map(df_prices.groupby('SecuritiesCode').ret.apply(lambda s: sharpe(s, lag)))\n        # days since last dividend\n        features['days_since_last_div'] = features.SecuritiesCode.map((df_prices.Date.iloc[-1] - df_prices.loc[lambda x: x.ExpectedDividend.notnull()].groupby('SecuritiesCode').Date.last()) / np.timedelta64(1,'D'))\n        # initiate dividend\n        features['first_div'] = features.SecuritiesCode.map(df_prices.groupby('SecuritiesCode').first_div.last())\n        # AdjustmentFactor\n        features['AdjustmentFactor'] = features.SecuritiesCode.map(df_prices.groupby('SecuritiesCode').AdjustmentFactor.apply(lambda s: (s!=1).astype(int).iloc[-1]))\n\n\n        '''\n        Secondary stock prices features\n        '''\n        # precalculate new columns\n        df_sec_prices['ret'] = df_sec_prices.groupby('SecuritiesCode').Close.pct_change()\n        df_sec_prices['dollar_traded'] = np.log(df_sec_prices.Volume * (df_sec_prices.Open + df_sec_prices.Close)/2 + 1)\n        # cross-sectional return & volatility\n        for n in [1,3]:\n            features[f'sec_cross_sect_ret_{n}'] = df_sec_prices.groupby('SecuritiesCode').ret.apply(lambda s: s.tail(n).sum()).mean()\n            features[f'sec_cross_sect_vol_{n}'] = df_sec_prices.groupby('SecuritiesCode').ret.apply(lambda s: s.tail(n).sum()).std()\n        # Change in volume\n        for lag in ['3d','1w']:\n            features[f'sec_volume_ma_pctg_ch_{lag}'] = df_sec_prices.groupby('SecuritiesCode').Volume.apply(lambda s: ma_pctg_ch(s, lag)).mean()\n        # volatility\n        for lag in ['1w','1m','3m']:\n            features[f'sec_volatility_{lag}'] = df_sec_prices.groupby('SecuritiesCode').ret.apply(lambda s: s.tail(LAGS[lag]).std()).mean()\n        # change in volatility\n        features['sec_volatility_diff'] = features['sec_volatility_1w'] - features['sec_volatility_1m']\n        # change in dollar value traded\n        for lag in ['1w','1m']:\n            features[f'sec_dollar_standard_dist_{lag}'] = df_sec_prices.groupby('SecuritiesCode').dollar_traded.apply(lambda s: standard_dist(s, lag)).mean()\n\n        '''\n        Time phase features\n        '''\n        # day in week\n        day_in_week_angle = (features.Date.dt.weekday / 5 * 2 * np.pi).iloc[-1]\n        features['day_in_week_sin'] = np.sin(day_in_week_angle)\n        features['day_in_week_cos'] = np.cos(day_in_week_angle)\n        # day in month\n        day_in_month_angle = ((features.Date.dt.day - 1) / 31 * 2 * np.pi).iloc[-1]\n        features['day_in_month_sin'] = np.sin(day_in_month_angle)\n        features['day_in_month_cos'] = np.cos(day_in_month_angle)\n        # week in year\n        week_in_year_angle = ((features.Date.dt.week - 1) / 52 * 2 * np.pi).iloc[-1]\n        features['week_in_year_sin'] = np.sin(week_in_year_angle)\n        features['week_in_year_cos'] = np.cos(week_in_year_angle)\n\n\n        '''\n        Financials features\n        '''\n        # convert string to numbers\n        fin_cols = ['NetSales','OperatingProfit','OrdinaryProfit','Profit','EarningsPerShare','TotalAssets','Equity','EquityToAssetRatio','BookValuePerShare',\n                    'ForecastNetSales','ForecastOperatingProfit','ForecastOrdinaryProfit','ForecastProfit','ForecastEarningsPerShare']\n        # clean numeric values\n        df_fins[fin_cols] = df_fins[fin_cols].replace('－',np.nan).astype(float)\n        # quarter forward fill\n        df_fins = df_fins.sort_values(['SecuritiesCode','TypeOfCurrentPeriod','Date']).reset_index(drop=True)\n        df_fins[fin_cols] = df_fins.groupby(['SecuritiesCode','TypeOfCurrentPeriod'])[fin_cols].ffill()\n        # overall forward fill\n        df_fins = df_fins.sort_values(['SecuritiesCode','Date']).reset_index(drop=True)\n        df_fins[fin_cols] = df_fins.groupby('SecuritiesCode')[fin_cols].ffill()\n        # drop invalid rows\n        df_fins = df_fins \\\n            .loc[lambda x: x.NetSales > 0] \\\n            .sort_values(['SecuritiesCode','Date']) \\\n            .reset_index(drop=True)\n        # define columns\n        df_fins['Close'] = df_fins.SecuritiesCode.map(df_prices.groupby('SecuritiesCode').Close.last())\n        df_fins['SalesToEquityRatio'] = df_fins['NetSales'] / df_fins['Equity']\n        df_fins['BookToMarketRatio'] = df_fins['Equity'] / df_fins['Close']\n        df_fins['ProfitoMarketRatio'] = df_fins['OperatingProfit'] / df_fins['Close']\n        df_fins['EarningToPriceRatio'] = df_fins['EarningsPerShare'] / df_fins['Close']\n        fin_cols_static = ['NetSales','OperatingProfit','OrdinaryProfit','Profit','EarningsPerShare','TotalAssets','Equity','BookValuePerShare',\n                            'ForecastNetSales','ForecastOperatingProfit','ForecastOrdinaryProfit','ForecastProfit','ForecastEarningsPerShare']\n        fin_cols_ratio = ['EquityToAssetRatio','SalesToEquityRatio','BookToMarketRatio','ProfitoMarketRatio','EarningToPriceRatio']\n        fin_cols = fin_cols_static + fin_cols_ratio\n        # fins feature calculation\n        df1 = df_fins.sort_values(['SecuritiesCode','TypeOfCurrentPeriod','Date']).reset_index(drop=True).groupby(['SecuritiesCode','TypeOfCurrentPeriod'])[fin_cols].nth(-1)\n        df2 = df_fins.sort_values(['SecuritiesCode','TypeOfCurrentPeriod','Date']).reset_index(drop=True).groupby(['SecuritiesCode','TypeOfCurrentPeriod'])[fin_cols].nth(-2)\n        df = df1.merge(df2, how='left', left_index=True, right_index=True)\n        for c in fin_cols:\n            if c in fin_cols_static:\n                df[f'{c}_pctg'] = (df[f'{c}_x'] - df[f'{c}_y']) / df[f'{c}_y'].abs()\n            elif c in fin_cols_ratio:\n                df[f'{c}_raw'] = df[f'{c}_x']\n                df[f'{c}_diff'] = df[f'{c}_x'] - df[f'{c}_y']\n        df = df.drop([c for c in df if c[-2:] in ['_x','_y']], axis=1).reset_index()\n        feats_fins = df_fins.sort_values(['SecuritiesCode','Date']).groupby('SecuritiesCode').last()['TypeOfCurrentPeriod'].reset_index()\n        feats_fins = feats_fins.merge(df, how='left', on=['SecuritiesCode','TypeOfCurrentPeriod']).drop('TypeOfCurrentPeriod', axis=1)\n        features = features.merge(feats_fins, how='left', on='SecuritiesCode')\n        # num days since last announcement\n        features['days_since_last_fin'] = (features.Date - features.SecuritiesCode.map(df_fins.groupby('SecuritiesCode').Date.last())) / np.timedelta64(1,'D')\n\n\n        '''\n        Post-processing\n        '''\n        cols = [c for c in features.columns if c not in ['RowId','Date','SecuritiesCode']]\n        features[cols] = features[cols].replace(np.inf, np.nan).replace(-np.inf, np.nan)\n        features[cols] = features[cols].fillna(features[cols].mean())\n        features[cols] = features[cols].astype(np.float32)\n\n        return features\n\n    \nelif FE=='ta':\n\n    def get_features(data):\n        df_prices, df_sec_prices, df_fins, df_opts, df_trades = tuple(data.values())\n    #     df_prices, df_sec_prices, df_fins, df_opts, df_trades = tuple(data.data.values())\n\n        # base table\n        features = df_prices.loc[lambda x: x.Date==x.Date.iloc[-1]][['RowId','Date','SecuritiesCode']]\n\n        # precalculate new columns\n        cols = [c for c in df_prices.columns.tolist()[3:] if c!='ExpectedDividend']\n        df_prices[cols] = df_prices.groupby('SecuritiesCode')[cols].ffill()\n        df_prices['ret'] = df_prices.groupby('SecuritiesCode').Close.pct_change()\n        ret_mkt = df_prices.groupby('Date').ret.mean()\n\n        # market return and volatility\n        for lag in ['3d','1w','1m','3m']:\n            features[f'ret_mkt_{lag}'] = ret_mkt.tail(LAGS[lag]).sum()\n            features[f'vol_mkt_{lag}'] = ret_mkt.tail(LAGS[lag]).std()\n\n        # TA feats\n        ta_feats = gen_ta_feats(df=df_prices, n_day_ma=52, n_day_scale=20)\n        features = features.merge(ta_feats, how='inner', on='SecuritiesCode')\n\n        '''\n        Post-processing\n        '''\n        cols = [c for c in features.columns if c not in ['RowId','Date','SecuritiesCode']]\n        features[cols] = features[cols].replace(np.inf, np.nan).replace(-np.inf, np.nan)\n        features[cols] = features[cols].fillna(features[cols].mean())\n        features[cols] = features[cols].astype(np.float32)\n\n        return features","metadata":{"_uuid":"18f34c4c-eadc-4ab7-bbaf-ee1753588b7f","_cell_guid":"4a637337-7541-4b8f-bdff-7aca913a0aef","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-02T11:31:52.390984Z","iopub.execute_input":"2022-07-02T11:31:52.39137Z","iopub.status.idle":"2022-07-02T11:31:52.448353Z","shell.execute_reply.started":"2022-07-02T11:31:52.391338Z","shell.execute_reply":"2022-07-02T11:31:52.447612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ndef update_data(test_start_date):\n    # load train + sup data\n    df_prices = pd.concat([pd.read_csv(f'{JPX_PATH}/{folder}/stock_prices.csv', parse_dates=['Date']) for folder in ['train_files','supplemental_files']]).reset_index(drop=True)\n    df_sec_prices = pd.concat([pd.read_csv(f'{JPX_PATH}/{folder}/secondary_stock_prices.csv', parse_dates=['Date']) for folder in ['train_files','supplemental_files']]).reset_index(drop=True)\n    df_fins = pd.concat([pd.read_csv(f'{JPX_PATH}/{folder}/financials.csv', parse_dates=['Date']) for folder in ['train_files','supplemental_files']]).reset_index(drop=True)\n    df_opts = pd.concat([pd.read_csv(f'{JPX_PATH}/{folder}/options.csv', parse_dates=['Date']) for folder in ['train_files','supplemental_files']]).reset_index(drop=True)\n    df_trades = pd.concat([pd.read_csv(f'{JPX_PATH}/{folder}/trades.csv', parse_dates=['Date']) for folder in ['train_files','supplemental_files']]).reset_index(drop=True)\n\n    # identify missing dates\n    if test_start_date.astype('datetime64[Y]').astype(int) + 1970 == 2021:\n        fe_end_date = np.datetime64('2021-10-27')\n#         fe_end_date = np.datetime64('2021-12-01')\n    else:\n        fe_end_date = data.last_date\n    extra_dates = df_prices.Date.drop_duplicates().loc[lambda x: (x > fe_end_date) & (x < test_start_date)].tolist()\n\n    # FE for missing dates\n    for i in range(len(extra_dates)):\n        data.push_forward([df.loc[lambda x: x.Date==extra_dates[i]] for df in [df_prices, df_sec_prices, df_fins, df_opts, df_trades]], append=False, last=False)\n    \n    # release memory\n    del df_prices, df_sec_prices, df_fins, df_opts, df_trades\n    gc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-02T11:31:52.449576Z","iopub.execute_input":"2022-07-02T11:31:52.45004Z","iopub.status.idle":"2022-07-02T11:31:52.46061Z","shell.execute_reply.started":"2022-07-02T11:31:52.450004Z","shell.execute_reply":"2022-07-02T11:31:52.459792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"'''\nFunction to get sub-columns from table for model fitting\n'''\ndef get_dataset(df, selected_feats, trn_val):\n    if trn_val=='val':\n        df = df.groupby('Date').sample(frac=1.0, random_state=SEED)\n    df = df.reset_index(drop=True)\n    grp = df.groupby('Date').size().tolist()\n    qid = df['Date']\n    X = df[selected_feats]\n    y = df['target_train']\n    target = df['Target']\n    header = df[id_cols]\n    return X, y, grp, qid, header, target\n\n'''\nFunction to predict scores within groups\n'''\ndef pred_score(model, X):\n    if MODEL=='reg':\n        return pd.Series(model.predict(X))\n    elif MODEL=='clf':\n        return pd.Series(model.predict_proba(X)[:,1])\n    elif MODEL=='clf3':\n        return pd.Series((model.predict_proba(X) * [-1,0,1]).sum(axis=1))\n\n'''\nFunction to transform model output to rank prediction table\n'''\ndef get_pred_df(header, pred_model, y_true_train, y_true, rank_ascending):\n    df_pred = pd.concat([header[['RowId','Date','SecuritiesCode']].assign(SecuritiesCode=lambda x: x.SecuritiesCode.astype(int)).reset_index(drop=True),\n                        pd.Series(pred_model).rename('pred_model').reset_index(drop=True),\n                        y_true_train.reset_index(drop=True),\n                        y_true.reset_index(drop=True)\n                        ], axis=1)\n    df_pred['Rank'] = df_pred.groupby('Date').pred_model.rank(method='first', ascending=rank_ascending).astype(int) - 1\n    return df_pred","metadata":{"execution":{"iopub.status.busy":"2022-07-02T11:31:52.461875Z","iopub.execute_input":"2022-07-02T11:31:52.462546Z","iopub.status.idle":"2022-07-02T11:31:52.478857Z","shell.execute_reply.started":"2022-07-02T11:31:52.462507Z","shell.execute_reply":"2022-07-02T11:31:52.477757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_stock_clust(ret, date, n_day, stock_list):\n    # raw correlation table\n    corr = ret.loc[lambda x: pd.to_datetime(x.Date)<=date].pivot(index='Date', columns='SecuritiesCode', values='ret').tail(n_day).corr()\n    corr = corr.reindex(index=stock_list, columns=stock_list)\n    cols = [c for c in corr if corr[c].notnull().sum()==0]\n    corr = corr.drop(cols, axis=0).drop(cols, axis=1)\n    stocks = corr.columns.tolist()\n\n    # clustering\n    pdist = spc.distance.pdist(corr.values)\n    linkage = spc.linkage(pdist, method='complete')\n    idx = spc.fcluster(linkage, 0.5 * pdist.max(), 'distance')\n    stock_corr_clust = pd.DataFrame({'SecuritiesCode':stocks, 'clust':idx}).assign(Date=date).sort_values('clust').reset_index(drop=True)\n    return stock_corr_clust","metadata":{"execution":{"iopub.status.busy":"2022-07-02T11:31:52.481328Z","iopub.execute_input":"2022-07-02T11:31:52.4816Z","iopub.status.idle":"2022-07-02T11:31:52.495049Z","shell.execute_reply.started":"2022-07-02T11:31:52.481565Z","shell.execute_reply":"2022-07-02T11:31:52.493956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Execution","metadata":{"execution":{"iopub.status.busy":"2022-06-27T14:24:06.821286Z","iopub.execute_input":"2022-06-27T14:24:06.821508Z","iopub.status.idle":"2022-06-27T14:24:14.792169Z","shell.execute_reply.started":"2022-06-27T14:24:06.821481Z","shell.execute_reply":"2022-06-27T14:24:14.791105Z"}}},{"cell_type":"code","source":"%%time\n\n# init env\nenv = jpx_tokyo_market_prediction.make_env()\niter_test = env.iter_test()\n\n# init variables\nif FE=='orig':\n    data = load_pkl(f'{FE_PATH}/data')\nelif FE=='ta':\n    data = load_pkl(f'{FE_PATH}/results (2)/data')\nsample_prediction_all = []\ndf_pred_val_all = []\nupdated_data = 0\nclose = []\ndf = pd.concat([pd.read_csv(f'{JPX_PATH}/train_files/stock_prices.csv'),\n                 pd.read_csv(f'{JPX_PATH}/supplemental_files/stock_prices.csv')]) \\\n    .loc[:, ['Date','SecuritiesCode','Close']]\nclose.append(df)\n\n# prepare feature means\nif FE=='orig':\n    features = pd.concat([pd.concat(load_pkl(f'{FE_PATH}/features/{filename}')) for filename in os.listdir(f'{FE_PATH}/features')]).sort_values('RowId').reset_index(drop=True)\nelif FE=='ta':\n    features1 = pd.concat([pd.concat(load_pkl(f'{FE_PATH}/results (1)/features/{filename}')) for filename in os.listdir(f'{FE_PATH}/results (1)/features')]).sort_values('RowId').reset_index(drop=True)\n    features2 = pd.concat([pd.concat(load_pkl(f'{FE_PATH}/results (2)/features/{filename}')) for filename in os.listdir(f'{FE_PATH}/results (2)/features')]).sort_values('RowId').reset_index(drop=True)\n    features = pd.concat([features1, features2]).reset_index(drop=True)\n    del features1, features2\n    gc.collect()\nmean = features.groupby('Date').mean().ffill()\nmean = mean.fillna(mean.mean())\nmean = mean.tail(20).mean()\ndel features\ngc.collect()\n\n# iterations\nfor df_prices, df_opts, df_fins, df_trades, df_sec_prices, sample_prediction in iter_test:\n    \n    # add new supplemental data for first iteration\n    date = np.datetime64(sample_prediction.Date.iloc[0])\n    if updated_data==0:\n        update_data(date)\n        updated_data = 1\n        \n    # append ret\n    close.append(df_prices.loc[:, ['Date','SecuritiesCode','Close']])\n    ret = pd.concat(close) \\\n        .sort_values(['Date','SecuritiesCode']) \\\n        .assign(ret = lambda x: x.groupby('SecuritiesCode').Close.pct_change()) \\\n        .loc[:, ['Date','SecuritiesCode','ret']] \\\n        .dropna() \\\n        .drop_duplicates(subset=['Date','SecuritiesCode']) \\\n        .reset_index(drop=True)\n        \n    # set date columns\n    for df in [df_prices, df_opts, df_fins, df_trades, df_sec_prices]:\n        df['Date'] = pd.to_datetime(df['Date'])\n        \n    # feature engineering of current date\n    data.push_forward([df_prices, df_sec_prices, df_fins, df_opts, df_trades], append=False, last=False)\n    features = data.curr_features\n    \n    # fillna\n    cols = [c for c in features.columns if c not in ['RowId','SecuritiesCode','Date']]\n    features[cols] = features[cols].fillna(mean[cols])\n    \n    # train-val split\n    full_data = features.assign(fold = -1,\n                                trn_val = 'val',\n                                Target = 0.0,\n                                target_train = 0.0)\n\n    # define column types\n    id_cols = ['RowId','Date','SecuritiesCode','fold','trn_val']\n    all_features = [c for c in list(full_data) if c not in id_cols and c not in ['target_train','Target']]\n    cat_features = ['AdjustmentFactor','first_div']\n    time_features = [c for c in all_features if '_mkt' in c] + \\\n                    [c for c in all_features if c[:4]=='sec_'] + \\\n                    [c for c in all_features if c[-4:] in ['_sin','_cos']]\n    stock_features = [c for c in all_features if c not in cat_features + time_features]\n\n    # scaling\n    scaler = load_pkl(f'{MODEL_PATH}/scaler4')\n    feats = time_features + stock_features\n    full_data[feats] = scaler.transform(full_data[feats]).astype(np.float32)\n\n    # drop market features\n    if DROP_MARKET_FEATS:\n        full_data = full_data.drop(time_features, axis=1)\n        all_features = [c for c in all_features if c not in time_features]\n\n    # PCA compression\n    if RUN_PCA:\n        if PCA_SPLIT==False:\n            pca = load_pkl(f'{MODEL_PATH}/pca')        \n            cols = [f'pc{x}' for x in range(pca.components_.shape[0])]\n            X = pd.DataFrame(pca.transform(full_data.loc[:, all_features]), columns=cols)\n            header = full_data.loc[:, [c for c in full_data.columns if c not in all_features]].reset_index(drop=True)\n            full_data = pd.concat([header, X], axis=1)  \n            all_features = cols.copy()\n            stock_features = None\n            time_features = None\n\n        elif PCA_SPLIT==True:\n            stock_feats = [c for c in all_features if c not in time_features]\n            market_feats = [c for c in all_features if c in time_features]\n            pca_stock = load_pkl(f'{MODEL_PATH}/pca_stock')\n            pca_market = load_pkl(f'{MODEL_PATH}/pca_market')\n            cols_stock = [f'pc_stock{x}' for x in range(pca_stock.components_.shape[0])]\n            cols_market = [f'pc_market{x}' for x in range(pca_market.components_.shape[0])]\n            X_stock = pd.DataFrame(pca_stock.transform(full_data.loc[:, stock_feats]), columns=cols_stock)\n            X_market = pd.DataFrame(pca_market.transform(full_data.loc[:, market_feats]), columns=cols_market)\n            header = full_data.loc[:, [c for c in full_data.columns if c not in all_features]].reset_index(drop=True)\n            full_data = pd.concat([header, X_stock, X_market], axis=1)\n            all_features = cols_stock + cols_market\n            stock_features = cols_stock\n            time_features = cols_market\n\n    # model prediction\n    df_pred_val = []\n    for seed in SEEDS:\n        for fold in range(N_FOLD):\n            X_val, y_val, grp_val, qid_val, header_val, target_val = get_dataset(full_data, SELECTED_FEATS, 'val')\n            model = load_pkl(f'{MODEL_PATH}/model{fold}_seed{seed}')\n            pred_val = pred_score(model, X_val)\n            df_pred_val.append(get_pred_df(header_val, pred_val, y_val, target_val, RANK_ASCENDING))\n    df_pred_val = pd.concat(df_pred_val).reset_index(drop=True)\n    df_pred_val = df_pred_val.groupby(['RowId','Date','SecuritiesCode']).mean().reset_index()\n    df_pred_val['Rank'] = df_pred_val.groupby('Date').pred_model.rank(method='first', ascending=False).astype(int) - 1\n\n    # cluster demean\n    if CLUSTER_DEMEAN:\n        df_clust = []\n        for date in df_pred_val.Date.unique():\n            stock_list = df_pred_val.loc[lambda x: x.Date==date].SecuritiesCode.tolist()\n            df_clust.append(get_stock_clust(ret, date, CLUST_N_DAY, stock_list))\n        df_clust = pd.concat(df_clust)\n        df_pred_val = df_pred_val.merge(df_clust, how='inner', on=['Date','SecuritiesCode'])\n        clust_mean = df_pred_val.groupby(['Date','clust']).pred_model.mean().reset_index().rename(columns={'pred_model':'pred_model_mean'})\n        df_pred_val = df_pred_val.merge(clust_mean, how='inner', on=['Date','clust'])\n        df_pred_val['pred_model_demean'] = df_pred_val.pred_model - df_pred_val.pred_model_mean\n        df_pred_val['Rank'] = df_pred_val.groupby('Date').pred_model_demean.rank(method='first', ascending=False).astype(int) - 1\n\n    # volatility penalty\n    if VOL_PENALTY:\n        std = ret.pivot(index='Date', columns='SecuritiesCode', values='ret') \\\n            .rolling(VOL_N_DAY).std() \\\n            .stack().reset_index() \\\n            .dropna() \\\n            .rename(columns={0:'std'}) \\\n            .assign(Date = lambda x: pd.to_datetime(x.Date))\n        df_pred_val = df_pred_val.merge(std, how='inner', on=['Date','SecuritiesCode'])\n        # identify best power and apply\n        best_p = VOL_POW\n        df_pred_val['pred_model_vol_penalty'] = df_pred_val.pred_model_demean / df_pred_val['std'].pow(best_p)\n        df_pred_val['Rank'] = df_pred_val.groupby('Date').pred_model_vol_penalty.rank(method='first', ascending=False).astype(int) - 1\n\n    # final submission\n    rnk = df_pred_val.set_index('SecuritiesCode').Rank\n    sample_prediction['Rank'] = sample_prediction['SecuritiesCode'].map(rnk)\n    sample_prediction['Rank'] = sample_prediction['Rank'].fillna(1000).rank(method='first', ascending=True).astype(int) - 1\n    env.predict(sample_prediction)\n    \n    # save results\n    sample_prediction_all.append(sample_prediction)\n    df_pred_val_all.append(df_pred_val)\n\n# output\nsample_prediction_all = pd.concat(sample_prediction_all).reset_index(drop=True)\ndf_pred_val_all = pd.concat(df_pred_val_all).reset_index(drop=True)\ndisplay(sample_prediction_all)\ndisplay(df_pred_val_all)\nif EXPORT:\n    sample_prediction_all.to_csv('sample_prediction_all.csv', index=False)\n    df_pred_val_all.to_csv('df_pred_val_all.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-02T11:31:52.496625Z","iopub.execute_input":"2022-07-02T11:31:52.497245Z","iopub.status.idle":"2022-07-02T11:31:52.735694Z","shell.execute_reply.started":"2022-07-02T11:31:52.497187Z","shell.execute_reply":"2022-07-02T11:31:52.73479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Debug","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}